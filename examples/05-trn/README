=======================================================================
    05 - NN Training Example
=======================================================================

A neural network stratified training job for Cu-Ag using a small Cu-Ag
dataset. Previously trained Cu.dat and Ag.dat elemental models are
provided in NNET/

NOTE: Due to the large amount of parsed files, the PARS directory has
been compressed, and must be uncompressed before use as shown below.

If there are any problems/questions, please feel free to post 
on the MAISE forum: https://harvey0.binghamton.edu/~akolmogo/forum/

=======================================================================
    REQUIRED FILES
=======================================================================
maise
setup
NNET/Ag.dat (elemental model file for silver)
NNET/Cu.dat (elemental model file for copper)
PARS/       (directory containing parsed structures for training/testing)

=======================================================================
    EXECUTION COMMAND
=======================================================================
tar -xvf PARS.tar.gz
maise 

=======================================================================
    EXPECTED OUTPUT
=======================================================================

=======================================================================
|               Module for Ab Initio Structure Evolution              |
|                        version     maise.2.7.00                     |
|                 https://github.com/maise-guide/maise                |
=======================================================================
|                            Model training                           |
=======================================================================

Loading list of parsed data from ./PARS/index.dat

Total number of parameters: 1902
BFGS2 relaxation: 1040 adjustable parameters

     1 1.1180920333757309     0.779057     5.034344     0.938831     7.022223
     2 0.6960607178739936     0.623539     1.941889     0.660513     2.726337
     3 0.6850056957471403     0.614721     1.897252     0.667552     2.662117
     4 0.5211515442095301     0.473093     1.372155     0.483252     1.881971
     5 0.5099660614521054     0.464685     1.318724     0.452605     1.799129
     6 0.4294059939604828     0.397024     1.026885     0.394001     1.314670
     7 0.4207317919420862     0.393404     0.936318     0.372292     1.171729
     8 0.3859472264759407     0.372363     0.637112     0.385694     0.692452
     9 0.3709924889644786     0.361193     0.531712     0.359914     0.555386
    10 0.3180404538496605     0.292409     0.785196     0.310415     1.171234
    11 0.3029784929310796     0.268414     0.882172     0.275594     1.324179
    12 0.2818223289225756     0.232829     0.996771     0.235597     1.488508
    13 0.2218729640238917     0.178247     0.829349     0.149274     1.105606
    14 0.2200354060205559     0.176288     0.826555     0.143381     1.095526
    15 0.2110124141907661     0.170570     0.779801     0.136566     0.951907
    16 0.1858536317908634     0.147264     0.711708     0.122819     0.743228
    17 0.1809204855374196     0.141292     0.709323     0.127782     0.724234
    18 0.1773182576461523     0.140074     0.682496     0.131033     0.681954
    19 0.1770199629961949     0.140012     0.679940     0.133166     0.678222
    20 0.1741263861961962     0.139429     0.654750     0.133563     0.652083
    21 0.1738370647766197     0.139393     0.652013     0.134465     0.649456
    22 0.1735662025065758     0.139018     0.652331     0.133140     0.650138
    23 0.1692417479924121     0.133422     0.653602     0.126255     0.659204
    24 0.1609869417523979     0.122811     0.653387     0.109419     0.696050
    25 0.1603812056273316     0.122182     0.652160     0.109272     0.698044
    26 0.1484934599119122     0.108304     0.637710     0.090951     0.803451
    27 0.1482996353341562     0.108158     0.636903     0.090374     0.802044
    28 0.1461686967319974     0.107291     0.623121     0.093051     0.779887
    29 0.1432621622458148     0.106286     0.602988     0.092614     0.741638
    30 0.1431168034517297     0.106214     0.602125     0.092674     0.739970
    31 0.1368941551187597     0.104557     0.554671     0.096384     0.661783
    32 0.1330867492694995     0.102175     0.535309     0.087945     0.596490
    33 0.1283144857352526     0.096675     0.529622     0.082158     0.546066
    34 0.1280465120565777     0.096315     0.529647     0.080681     0.537465
    35 0.1277836381518190     0.095818     0.530699     0.080642     0.531624
    36 0.1272956292691285     0.095152     0.530802     0.078595     0.522475
    37 0.1269481406148483     0.094540     0.531829     0.078760     0.518748
    38 0.1260405589770289     0.093657     0.529472     0.076123     0.508151
    39 0.1257081002595003     0.093256     0.529146     0.076432     0.505791
    40 0.1240384513640250     0.092431     0.519233     0.073314     0.487430
    41 0.1237555161762374     0.092220     0.518048     0.073549     0.485213
    42 0.1200604693852963     0.089426     0.502868     0.067309     0.458537
    43 0.1145713196341067     0.082330     0.500148     0.065068     0.460999
    44 0.1124988429123395     0.079595     0.499055     0.060408     0.461611
    45 0.1078001986396393     0.077286     0.471747     0.069355     0.437885
    46 0.1078001986396393     0.077286     0.471747     0.069355     0.437885
    47 0.1073904770345251     0.076844     0.470911     0.065770     0.437413
    48 0.1048006396898276     0.074107     0.465164     0.058103     0.435108
    49 0.1014057362667853     0.071863     0.449113     0.053008     0.430795
    50 0.1012670083787643     0.071755     0.448558     0.053319     0.430890
    51 0.0957231098856056     0.066507     0.432160     0.050767     0.442618
    52 0.0932002483577120     0.063679     0.427190     0.049125     0.466423
    53 0.0917988839303953     0.061282     0.429045     0.050250     0.486529
    54 0.0910722020727892     0.060592     0.426796     0.053153     0.490101
    55 0.0908187766689158     0.060749     0.423778     0.052922     0.485737
    56 0.0853764107532381     0.061346     0.372731     0.054808     0.400505
    57 0.0851848176373933     0.061598     0.369351     0.054781     0.394877
    58 0.0835277803504533     0.062828     0.345506     0.054043     0.353445
    59 0.0835277803504533     0.062828     0.345506     0.054043     0.353445
    60 0.0833608719677904     0.062680     0.344974     0.053839     0.353306
    61 0.0812282380393768     0.060451     0.340575     0.051596     0.357926
    62 0.0806378555914929     0.059544     0.341346     0.049437     0.359621
    63 0.0806168777641195     0.059505     0.341419     0.049378     0.359696
    64 0.0799145435864966     0.058453     0.342073     0.050011     0.358978
    65 0.0757353341443471     0.053733     0.335034     0.043989     0.370238
    66 0.0757085648638957     0.053705     0.334968     0.043968     0.370306
    67 0.0748488329135596     0.052563     0.334496     0.045975     0.375918
    68 0.0742642142695847     0.052009     0.332769     0.049067     0.376980
    69 0.0742304678232992     0.051979     0.332656     0.049405     0.376869
    70 0.0657666438705317     0.044233     0.305509     0.037792     0.279815
    71 0.0656800783556583     0.044078     0.305658     0.037445     0.279633
    72 0.0646485501177054     0.042209     0.307382     0.034190     0.280213
    73 0.0616876821710277     0.039005     0.299994     0.038833     0.274700
    74 0.0615560175018376     0.038871     0.299617     0.039061     0.274532
    75 0.0580548413474561     0.034041     0.295205     0.034560     0.283270
    76 0.0568977102859830     0.033205     0.290032     0.029878     0.270546
    77 0.0568849179310029     0.033194     0.289983     0.030018     0.270419
    78 0.0558132528193423     0.032692     0.283962     0.032059     0.258605
    79 0.0541632207954977     0.031565     0.276293     0.029180     0.244145
    80 0.0531548561381398     0.030546     0.273069     0.025741     0.237808
    81 0.0528305033159204     0.030139     0.272371     0.025998     0.237820
    82 0.0528305033159204     0.030139     0.272371     0.025998     0.237820
    83 0.0526418307366981     0.029804     0.272383     0.025992     0.237839
    84 0.0521418195355746     0.029235     0.271019     0.026580     0.238944
    85 0.0517903310983100     0.029305     0.268052     0.027204     0.238026
    86 0.0517702805864457     0.029324     0.267818     0.027154     0.238015
    87 0.0505888609858964     0.029477     0.258082     0.029761     0.248533
    88 0.0505643383929177     0.029507     0.257754     0.029521     0.248645
    89 0.0503636028645579     0.029769     0.255008     0.028516     0.248819
    90 0.0501716544020315     0.030175     0.251612     0.027797     0.245728
    91 0.0498634820975633     0.030730     0.246498     0.027628     0.240927
    92 0.0495612318352680     0.031248     0.241483     0.028233     0.236370
    93 0.0494199721299130     0.031472     0.239181     0.029254     0.234238
    94 0.0482010918490201     0.032798     0.221724     0.029875     0.216803
    95 0.0481677373019406     0.032823     0.221290     0.030039     0.216377
    96 0.0476666182603564     0.033152     0.214992     0.029714     0.212075
    97 0.0476147555404036     0.033190     0.214308     0.029818     0.211590
    98 0.0464873891768338     0.033809     0.200282     0.032713     0.201242
    99 0.0463416879402518     0.033931     0.198132     0.032715     0.198361
   100 0.0448656198015112     0.034360     0.181099     0.033298     0.171675

ERROR ECNT CALLS =    574
ERROR FCNT CALLS =    331
TOT. RESI. ERROR =  0.002013  1.609503 -1.607490 (final,initial,difference)


 job times: real= 2.00   user= 30.19   sys= 0.31   total CPU= 30.50 (sec)

Stand. dev. ENE           1.388217                        396
Train error ENE FRC TOT   0.034360  0.181099  0.029612    357    906
Test  error ENE FRC TOT   0.033298  0.171675  0.034558     39    102

=======================================================================
    OUTPUT FILES
=======================================================================

NNET/model          trained model file
NNET/err-ene.dat    energy error of each structure
NNET/err-frc.dat    force error of each structure
NNET/err-out.dat    BFGS/CG optimization of NN parameters at each step

======================================================================= 
